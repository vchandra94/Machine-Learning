{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Question-1)  What is Simple Linear Regression (SLR)? Explain its purpose.**\n",
        "\n",
        "**Answer-1) **\n",
        "Here's an explanation of Simple Linear Regression (SLR).\n",
        "\n",
        "Simple Linear Regression (SLR) is a statistical method used to model the relationship between two continuous variables. It aims to find the best-fitting straight line that describes how one variable (the dependent variable) changes as the other variable (the independent variable) changes.\n",
        "\n",
        "\n",
        "1. \"Simple\" means we are using only one independent variable to predict the dependent variable.\n",
        "\n",
        "2. \"Linear\" means we assume the relationship between the two variables can be best represented by a straight line.\n",
        "\n",
        "The EquationThe relationship in SLR is described by a simple mathematical formula, which is the equation for a straight line:$$Y = \\beta_0 + \\beta_1X + \\epsilon$$\n",
        "\n",
        "Let's break this down:$Y$ is the dependent variable (the outcome you are trying to predict, e.g., exam score).5$X$ is the independent variable (the predictor you are using, e.g., hours of study).6$\\beta_0$ (Beta-nought) is the y-intercept.7 This is the predicted value of 8$Y$ when 9$X$ is equal to 0.10$\\beta_1$ (Beta-one) is the slope of the line. This is the most important part. It tells us how much 11$Y$ is expected to change for every one-unit increase in 12$X$.13If 14$\\beta_1$ is positive, 15$Y$ tends to increase as 16$X$ increases.17If $\\beta_1$ is negative, $Y$ tends to decrease as $X$ increases.$\\epsilon$ (Epsilon) is the error term.18 This accounts for the random variation and the fact that the data points don't fall perfectly on the line.19 It's the difference between the actual value and the predicted value.\n",
        "\n",
        "The goal of SLR is to find the values for 20$\\beta_0$ and 21$\\beta_1$ that create the \"line of best fit\"‚Äîthe line that comes closest to all the data points, typically by minimizing the sum of the squared errors (a method called Ordinary Least Squares).22\n",
        "\n",
        "**Purpose of Simple Linear Regression**\n",
        "\n",
        "The main purposes are:\n",
        "\n",
        "1. Prediction:\n",
        "Estimate or predict the value of\n",
        "ùëå\n",
        "Y for a given\n",
        "ùëã\n",
        "X.\n",
        "Example: Predicting a student‚Äôs exam score (Y) based on hours studied (X).\n",
        "\n",
        "2. Understanding relationships:\n",
        "Measure how strongly and in what direction (positive/negative) the independent variable affects the dependent variable.\n",
        "Example: Understanding whether advertising spend influences sales.\n",
        "\n",
        "3. Quantifying effect:\n",
        "The slope (\n",
        "ùõΩ\n",
        "1\n",
        "Œ≤\n",
        "1\n",
        "\t‚Äã\n",
        "\n",
        ") tells you how much\n",
        "ùëå\n",
        "Y changes when\n",
        "ùëã\n",
        "X increases by one unit.\n",
        "\n",
        "4. Trend analysis:\n",
        "Identify linear trends in data over time or other continuous variables.\n",
        "\n",
        "\n",
        "**Example**\n",
        "\n",
        "Suppose a company finds that sales increase as advertising spending increases.\n",
        "By fitting a simple linear regression model:\n",
        "\n",
        "Sales\n",
        "=\n",
        "25\n",
        "+\n",
        "3.5\n",
        "√ó\n",
        "(\n",
        "Advertising¬†Spend\n",
        ")\n",
        "Sales=25+3.5√ó(Advertising¬†Spend)\n",
        "\n",
        "The intercept (25) means if no money is spent on advertising, expected sales are 25 units.\n",
        "\n",
        "The slope (3.5) means every extra ‚Çπ1 spent on advertising increases sales by 3.5 units."
      ],
      "metadata": {
        "id": "ADey6pwnwgNN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question-2) What are the key assumptions of Simple Linear Regression?**\n",
        "\n",
        "**Answer-2)**\n",
        "\n",
        "For a Simple Linear Regression (SLR) model to produce a reliable and unbiased result, it must satisfy four key assumptions. These assumptions are often remembered by the acronym LINE:\n",
        "\n",
        "1. Linearity\n",
        "\n",
        "2. Independence\n",
        "\n",
        "3. Normality\n",
        "\n",
        "4. Equal variance (Homoscedasticity)\n",
        "\n",
        "These assumptions primarily relate to the residuals (the errors, or the difference between the actual data points and the regression line), not the variables themselves.\n",
        "\n",
        "1. **Linearity**\n",
        "\n",
        "    This is the most fundamental assumption. It states that there is a linear (straight-line) relationship between the independent variable (5$X$) and the dependent variable (6$Y$).7Why it matters: If the relationship isn't linear (e.g., it's curved), fitting a straight line to it will result in a poor-fitting model that makes inaccurate predictions.8How to check: Create a scatter plot of your 9$X$ and 10$Y$ variables.11 The points should appear to follow a general straight-line pattern, not a U-shape, S-shape, or any other distinct curve.12\n",
        "\n",
        "2. **Independence**\n",
        "\n",
        "    This assumption states that the residuals (errors) are independent of each other. This means that the error for one observation does not influence the error for any other observation.\n",
        "\n",
        "\n",
        "    a) Why it matters: This is a common issue in time-series data, where what happens one day (e.g., high sales) can influence what happens the next. When errors are correlated (a condition called autocorrelation), the model's precision is often overestimated, leading to false confidence in the results.\n",
        "\n",
        "    b) How to check: Plot the residuals in the order they were collected (e.g., over time). You should see a random scatter around zero, with no clear patterns like a wave or a consistent upward/downward trend.\n",
        "\n",
        "3. **Normality**\n",
        "\n",
        "    This assumption states that the residuals are normally distributed. It does not mean that the $X$ or $Y$ variables themselves must be normally distributed.\n",
        "\n",
        "    a) Why it matters: The normal distribution of residuals is necessary for most of the statistical tests associated with regression (like calculating p-values and confidence intervals) to be valid.\n",
        "\n",
        "    b) How to check: Use a Q-Q (Quantile-Quantile) plot.20 If the residuals are normally distributed, the points on this plot will fall closely along a straight diagonal line.21 A histogram of the residuals can also be used; it should look roughly like a symmetrical \"bell curve.\"\n",
        "\n",
        "4. **Equal Variance (Homoscedasticity)**\n",
        "\n",
        "    This assumption, also known as homoscedasticity (ho-mo-skeh-das-TISS-ih-tee), states that the residuals have constant variance at every level of the independent variable (23$X$).\n",
        "\n",
        "    In simpler terms, the \"spread\" or \"scatter\" of the data points around the regression line should be roughly the same from the left side of the graph to the right side.\n",
        "\n",
        "    a) Why it matters: The opposite condition is called heteroscedasticity (when the spread changes, often fanning out like a cone).26 When this happens, the model's predictions may be more reliable for some $X$ values and less reliable for others, and the standard errors will be biased.\n",
        "\n",
        "    b) How to check: Create a residual plot (plotting the predicted values or 27$X$ values on the horizontal axis and the residuals on the vertical axis).The points should form a random, horizontal \"cloud\" around the zero line, with no cone shape, funnel, or other systematic pattern."
      ],
      "metadata": {
        "id": "NLOv2N8vwhTX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question-3) Write the mathematical equation for a simple linear regression model and explain each term.**\n",
        "\n",
        "**Answer-3)**\n",
        "\n",
        "Here is the mathematical equation for a simple linear regression model, with a breakdown of each component.The equation for the population model (the true, underlying relationship we are trying to estimate) is:$$Y = \\beta_0 + \\beta_1X + \\epsilon$$\n",
        "\n",
        "Here is an explanation of each term:\n",
        "\n",
        "1. $Y$ (The Dependent Variable): This is the outcome or response variable. It's the variable you are trying to understand or predict.Example: Exam score.\n",
        "\n",
        "2. $X$ (The Independent Variable): This is the predictor or explanatory variable. It's the variable you are using to make the prediction.Example: Hours spent studying.\n",
        "\n",
        "3. $\\beta_0$ (Beta-nought / The Intercept): This is the y-intercept of the regression line. It is the predicted value of $Y$ when $X$ is equal to 0. It represents the baseline or starting value of $Y$ before any effect of $X$ is considered.Example: The predicted exam score for a student who studied for 0 hours.\n",
        "\n",
        "4. $\\beta_1$ (Beta-one / The Slope): This is the slope coefficient for the independent variable $X$. This is often the most important term, as it quantifies the relationship between $X$ and $Y$. It represents the average change in $Y$ for every one-unit increase in $X$.  \n",
        "\n",
        "   Example: For every 1 additional hour a student studies, their exam score is predicted to change by $\\beta_1$ points.\n",
        "   \n",
        "   a) If $\\beta_1$ is positive, $X$ and $Y$ have a positive relationship (as $X$ increases, $Y$ increases).\n",
        "   \n",
        "   b) If $\\beta_1$ is negative, $X$ and $Y$ have a negative relationship (as $X$ increases, $Y$ decreases).\n",
        "   \n",
        "5. $\\epsilon$ (Epsilon / The Error Term): This is the residual or random error. It represents the part of $Y$ that cannot be explained by the model. It accounts for all the random variation and other factors not included in the model that affect $Y$. It is the difference between the actual observed value of $Y$ and the value predicted by the line.\n",
        "\n",
        "Example: Two students study for the same 5 hours ($X$), but one gets a 90 and the other gets a 92. That 2-point difference is captured by the error term.\n"
      ],
      "metadata": {
        "id": "YIUVQsVR09Sq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question-4) Provide a real-world example where simple linear regression can be applied.**\n",
        "\n",
        "**Answer-4)**\n",
        "\n",
        "Here's a classic real-world example of how simple linear regression is used in business.\n",
        "\n",
        "Scenario: Predicting Product Sales Using Advertising Spend\n",
        "A marketing manager for an e-commerce company wants to understand the effectiveness of their monthly advertising budget.\n",
        "\n",
        "Goal (Understanding): Does spending more on ads actually lead to more sales? And if so, by how much?\n",
        "\n",
        "Goal (Prediction): If the company sets an ad budget of $5,000 for next month, how much revenue can they expect to generate?\n",
        "\n",
        "1. The VariablesThe manager first identifies the two variables for the model:\n",
        "\n",
        "   Independent Variable (1$X$): Monthly Ad Spend (in dollars)2This is the variable the company can control (the predictor).\n",
        "   \n",
        "   Dependent Variable ($Y$): Monthly Sales Revenue (in dollars)This is the variable they want to predict (the outcome).\n",
        "\n",
        "\n",
        "2. Data Collection\n",
        "The manager collects data from the past 12 months:\n",
        "\n",
        "Month,Ad Spend (X),Sales Revenue (Y)\n",
        "Jan,\"$2,000\",\"$45,000\"\n",
        "Feb,\"$1,500\",\"$38,000\"\n",
        "Mar,\"$1,800\",\"$41,000\"\n",
        "Apr,\"$3,000\",\"$58,000\"\n",
        "...,...,...\n",
        "Dec,\"$3,500\",\"$65,000\"\n",
        "\n",
        "3. Running the RegressionAfter plotting the data on a scatter plot and seeing a clear linear trend, the manager runs a simple linear regression analysis. The analysis produces the following model equation:$$\\hat{Y} = 10,000 + 16X$$\n",
        "\n",
        "4. Interpretation and Action\n",
        "\n",
        "    This model provides two crucial, actionable insights:\n",
        "\n",
        "    a) The Intercept($\\hat{\\beta}_0 = 10,000$):\n",
        "    \n",
        "    Interpretation: The model predicts that if the company spent $0 on advertising, it would still generate $10,000 in sales.Business Meaning: This is the baseline sales revenue, likely coming from repeat customers, brand recognition, and word-of-mouth.\n",
        "    \n",
        "    b) The Slope ($\\hat{\\beta}_1 = 16$):Interpretation: For every $1 additional dollar spent on advertising, the model predicts an increase of $16 in sales revenue.Business Meaning: This is the Return on Ad Spend (ROAS). The manager can now confidently say that the ad budget has a strong, positive, and quantifiable effect on sales.\n",
        "\n",
        "5. Making PredictionsNow, the manager can answer the second goal: \"What happens if we spend $5,000 next month?\"$$\\hat{Y} = 10,000 + 16 \\times (5,000)$$$$\\hat{Y} = 10,000 + 80,000$$$$\\hat{Y} = 90,000$$The model predicts that a monthly ad spend of $5,000 will result in approximately $90,000 in sales revenue. This helps the company set realistic budgets and forecast performance.\n",
        "\n",
        "\n",
        "Another Common Example\n",
        "\n",
        "Real Estate: Using the square footage of a house ($X$) to predict its selling price ($Y$).  \n",
        "A model like Price = 50,000 + 210(SquareFootage) would suggest a baseline land value of $50,000 and an additional $210 in value for every extra square foot of space."
      ],
      "metadata": {
        "id": "8ILZVfSc3biT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question-5) What is the method of least squares in linear regression?**\n",
        "\n",
        "**Answer-5)**\n",
        "\n",
        "The method of least squares finds the regression line by minimizing the sum of the squared differences between the observed values and the values predicted by the model.\n",
        "\n",
        "In other words, it chooses the line that makes the vertical distances (errors or residuals) between the actual data points and the predicted values as small as possible on average."
      ],
      "metadata": {
        "id": "hap71aOk5Voh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question-6) What is Logistic Regression? How does it differ from Linear Regression?**\n",
        "\n",
        "**Answer-6)**\n",
        "\n",
        "Logistic Regression is a supervised machine learning algorithm used for classification problems, especially binary classification (where the output variable has two possible outcomes, such as Yes/No, 0/1, Spam/Not Spam, etc.).\n",
        "\n",
        "Despite its name, logistic regression is not used for regression tasks ‚Äî it is used to predict categorical outcomes.\n",
        "\n",
        "Purpose\n",
        "\n",
        "Logistic Regression predicts the probability that a given input belongs to a certain class.\n",
        "\n",
        "The model uses the logistic (sigmoid) function to map the output of a linear equation to a value between 0 and 1, which can then be interpreted as a probability.\n",
        "\n",
        "\n",
        "**Linear regression** is used to predict a continuous value (a number). Think of it as answering \"How much?\"\n",
        "\n",
        "How much will this house cost? ($750,000)\n",
        "\n",
        "How many sales will we get? (1,250)\n",
        "\n",
        "What will the temperature be tomorrow? (78.5 degrees)\n",
        "\n",
        "It works by fitting the best possible straight line to the data. The output can be any number on a continuous scale (it can go to positive or negative infinity).\n",
        "\n",
        "wheras,\n",
        "\n",
        "**Logistic regression** is used to predict a categorical outcome (a class or label). Think of it as answering \"Which one?\" or \"Yes/No?\"\n",
        "\n",
        "Will this customer click the ad? (Yes or No)\n",
        "\n",
        "Is this email spam or not spam?\n",
        "\n",
        "Will this patient be readmitted to the hospital? (Yes or No)\n",
        "\n",
        "It doesn't output a number like 750,000. Instead, it outputs a probability‚Äîa value between 0 and 1. For example, it might predict a \"0.85\" probability that a customer will click an ad. We can then use a threshold (like 0.5) to classify the outcome: since 0.85 is greater than 0.5, we classify it as \"Yes.\"\n",
        "\n",
        "Because it has to output a probability between 0 and 1, it doesn't use a straight line. It uses an S-shaped (sigmoid) curve that squashes any input, no matter how large or small, into that 0-to-1 range.\n",
        "\n",
        "In short: Use linear regression to predict a number. Use logistic regression to predict a category."
      ],
      "metadata": {
        "id": "lMwgHFTU54px"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question-7) Name and briefly describe three common evaluation metrics for regression models.**\n",
        "\n",
        "**Answer-7)**\n",
        "\n",
        "Here are three common metrics used to evaluate regression models (models that predict continuous numbers).\n",
        "\n",
        "1. Mean Absolute Error (MAE)\n",
        "\n",
        "    This metric measures the average of the absolute differences between your model's predictions and the actual, true values.\n",
        "\n",
        "    a) What it tells you: On average, how far off your predictions are.\n",
        "\n",
        "    b) Interpretation: An MAE of 10 means your predictions are, on average, 10 units away from the real value (e.g., $10 off for a price prediction, 10 degrees off for a temperature prediction).\n",
        "\n",
        "    c) Key Trait: It's straightforward to understand and is less sensitive to large, infrequent errors (outliers) than RMSE.\n",
        "\n",
        "2. Root Mean Squared Error (RMSE)\n",
        "\n",
        "    This is one of the most popular metrics. It's the square root of the average of the squared errors.\n",
        "\n",
        "    a) What it tells you: The \"typical\" or \"standard\" distance between your predictions and the actual values.\n",
        "\n",
        "    b) Interpretation: Like MAE, it's in the same units as your target variable (e.g., an RMSE of $15).\n",
        "\n",
        "    c) Key Trait: Because it squares the errors before averaging, it penalizes large errors much more heavily than small ones. A single very wrong prediction will increase the RMSE more than it increases the MAE.\n",
        "\n",
        "3. R-squared (R¬≤ or Coefficient of Determination)\n",
        "\n",
        "\n",
        "    This metric is different; it measures how well your model fits the data rather than the absolute error.\n",
        "\n",
        "    a) What it tells you: The proportion (or percentage) of the variance in the target variable that is \"explained\" by your model's inputs.\n",
        "\n",
        "    b) Interpretation: It's a score between 0 and 1 (or 0% to 100%).\n",
        "\n",
        "    An R¬≤ of 0.82 means that 82% of the changes in the target variable (e.g., house prices) can be explained by your model's features (e.g., square footage, location).\n",
        "\n",
        "    An R¬≤ of 0 means your model is no better than just predicting the average of all the target values.\n",
        "\n",
        "    c) Key Trait: It provides a relative measure of \"goodness-of-fit,\" but it doesn't tell you the magnitude of your average error.\n",
        "\n"
      ],
      "metadata": {
        "id": "P_Q0xPkp7S2d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question-8) What is the purpose of the R-squared metric in regression analysis?**\n",
        "\n",
        "**Answer-8)**\n",
        "\n",
        "The purpose of the R-squared (R¬≤) metric, also known as the coefficient of determination, is to measure the \"goodness-of-fit\" of a regression model.\n",
        "\n",
        "In simple terms, it tells you what percentage of the variation in the target variable (what you're trying to predict) can be \"explained\" by your model's independent variables (what you're using to predict).\n",
        "\n",
        "Purpose\n",
        "\n",
        "1. Measures Goodness of Fit\n",
        "R¬≤ tells how well the model fits the data ‚Äî the higher the R¬≤, the better the fit.\n",
        "\n",
        "2. Explains Variability\n",
        "Shows how much of the variation in the dependent variable is captured by the model.\n",
        "\n",
        "3. Model Comparison\n",
        "Useful for comparing different regression models ‚Äî a model with a higher R¬≤ (on the same dataset) generally fits better.\n",
        "\n",
        "\n",
        "In short:\n",
        "\n",
        "R-squared measures how well your regression model explains the data‚Äôs variability ‚Äî it tells you the ‚Äúgoodness of fit‚Äù of your model."
      ],
      "metadata": {
        "id": "qFO0TXwO8vQx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Question-9) Write Python code to fit a simple linear regression model using scikit-learn\n",
        "and print the slope and intercept\n",
        "\n",
        "Answer-9)\n",
        "\"\"\"\n",
        "\n",
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Sample data (X: independent variable, y: dependent variable)\n",
        "X = np.array([1, 2, 3, 4, 5]).reshape(-1, 1)   # reshape for sklearn (2D)\n",
        "y = np.array([2, 4, 5, 4, 5])\n",
        "\n",
        "# Create and fit the linear regression model\n",
        "model = LinearRegression()\n",
        "model.fit(X, y)\n",
        "\n",
        "# Print the slope (coefficient) and intercept\n",
        "print(\"Slope (Œ≤1):\", model.coef_[0])\n",
        "print(\"Intercept (Œ≤0):\", model.intercept_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "355uOSRQ9o1x",
        "outputId": "8de6c94d-5552-4155-8172-5eaaf6cc97b8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Slope (Œ≤1): 0.6\n",
            "Intercept (Œ≤0): 2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question-10) How do you interpret the coefficients in a simple linear regression model?**\n",
        "\n",
        "**Answer-10)**\n",
        "\n",
        "In a simple linear regression model, you have an equation for a straight line:y = b‚ÇÅx + b‚ÇÄThe two coefficients you need to interpret are the intercept ($b_‚ÇÄ$) and the slope ($b_‚ÇÅ$).\n",
        "\n",
        "1. Interpreting the Intercept ($b_‚ÇÄ$)The intercept is the predicted value of the dependent variable (y) when the independent variable (x) is equal to zero.\n",
        "\n",
        "    What it represents: It's the starting point or baseline value of your model. It's where the regression line crosses the vertical y-axis.\n",
        "    \n",
        "    Example: Imagine a model that predicts a student's final exam score based on the number of hours they studied:Score = 5 * Hours_Studied + 65In this model, the intercept is 65. You would interpret it as: \"A student who studied for zero hours is predicted to get a score of 65 on the exam.\"\n",
        "    \n",
        "    Important Caveat: The intercept's interpretation is only meaningful if it's plausible for the independent variable (x) to be zero. For instance, if you're predicting a person's weight based on their height, an intercept for \"zero height\" is mathematically necessary for the line but has no practical, real-world meaning.\n",
        "\n",
        "2. Interpreting the Slope ($b_‚ÇÅ$)\n",
        "\n",
        "    The slope represents the predicted change in the dependent variable (y) for a one-unit increase in the independent variable (x). This is often the most important part of the model.\n",
        "    \n",
        "    What it represents: It tells you the magnitude and direction of the relationship between your two variables.\n",
        "    \n",
        "    Example (continued): Using the same model:Score = 5 * Hours_Studied + 65The slope is 5. You would interpret it as: \"For every one additional hour a student studies, their predicted exam score increases by 5 points.\"\n",
        "    \n",
        "    The sign of the slope is also crucial:\n",
        "    \n",
        "    Positive Slope (+): Indicates a positive relationship. As x increases, y is predicted to increase.\n",
        "    \n",
        "    Negative Slope (-): Indicates a negative relationship. As x increases, y is predicted to decrease. (For example, if the model was Car_Value = -2000 * Age_in_Years + 30000, the car's value decreases by $2,000 for each additional year of age)"
      ],
      "metadata": {
        "id": "v1Ju9JRZ-OVi"
      }
    }
  ]
}